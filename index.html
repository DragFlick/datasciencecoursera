<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/pygment_trac.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <title>Practical Machine Learning - Final Project Report by DragFlick</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <h1>Practical Machine Learning - Final Project Report</h1>
        <h2>Machine Learning</h2>
        <a href="https://github.com/DragFlick/datasciencecoursera" class="button"><small>View project on</small> GitHub</a>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <div id="header">
<h1>
<a id="practical-machine-learning---final-project-report" class="anchor" href="#practical-machine-learning---final-project-report" aria-hidden="true"><span class="octicon octicon-link"></span></a>Practical Machine Learning - Final Project Report</h1>
<h4>
<a id="chitresh-pandey" class="anchor" href="#chitresh-pandey" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Chitresh Pandey</em>
</h4>
</div>

<p>The Project Involves analyzing the Data collected in a controlled experient on 6 subjects. The activity involved here is “Unilateral Dumbbell Biceps Curl” . The data was collected for 5 different methods for the activity denoted as ( A , B , C , D ,E) . Out of 5, only A is the correct method .</p>

<p>A - Exactly as per specification</p>

<p>B - Throwing the elbows to the front</p>

<p>C - Lifting the dumbbell only halfway</p>

<p>D - Lowering the dumbbell only halfway</p>

<p>E - Throwing the hips to the front</p>

<p>Now, here we can pose 2 questions</p>

<p>Q1 . Can we classify that a person is doing the “Unilateral DumbBell Biceps Curl” correctly or incorrectly through a given dataset of specific measurements ?</p>

<p>Q2 . If the person is classified as doing the “Unilateral Dumbbell Biceps Curl” incorrectly , can we further classify him/her into B,C,D or E ?</p>

<p>The data for analysis is provided for by</p>

<p>Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers’ Data Classification of Body Postures and Movements. Proceedings of 21st Brazilian Symposium on Artificial Intelligence. Advances in Artificial Intelligence - SBIA 2012. In: Lecture Notes in Computer Science. , pp. 52-61. Curitiba, PR: Springer Berlin / Heidelberg, 2012. ISBN 978-3-642-34458-9. DOI: 10.1007/978-3-642-34459-6_6.</p>

<p>Loading the necessary libraries and the analysis data . Once the Experiment data is loaded dividing the data into Training and Testing samples .</p>

<p>Loading the Experiment data and slicing it into Testing and Training Sets</p>

<pre><code>ExpData &lt;- read.csv("./pml-training.csv") 
set.seed(4868086)
inTrain &lt;- createDataPartition( y = ExpData$classe , p = 0.7 , list = FALSE)
Training &lt;- ExpData[inTrain , ]
Testing &lt;- ExpData[-inTrain , ]
rm("inTrain")</code></pre>

<p>Now creating a Transform function to manage the tranformations that the Training and Testing data may have to undergo.</p>

<pre><code>Transform &lt;- function(DataSet)
        {
                DataSet[is.na(DataSet)] &lt;- 0
                s_data &lt;- subset(DataSet , 
                                 select = -c(X,user_name,raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp))
                class &lt;- s_data$classe
                s_data &lt;- subset(s_data , select = -classe)
                data &lt;- cbind(class , s_data)
                return(data)
        }</code></pre>

<p>Once we have the Transformed Training and Testing data , identifying the near zero covariates for both Training data and removing them from both Training and Testing dataset.</p>

<pre><code>Training &lt;- Transform(Training)
Testing  &lt;- Transform(Testing)

# Identifying the Near Zero CoVariates in Training set and removing them from both Training and Testing data

NZV &lt;- nearZeroVar(Training , saveMetrics=TRUE)
Training &lt;- Training[ ,!NZV$nzv]
Testing  &lt;- Testing[  ,!NZV$nzv]</code></pre>

<p>Calculating a CoVariance matrix to identify the Correlated Covariates</p>

<p>Looking at the Co-Relation Matrix we obzerve a high degree of Co-Relation between multiple CoVariates . We go ahead with Principal Componet Analyis (PCA) to reduce the number of Covariates . We go ahead with 2 models within PCA .First Model comprises of 30 PCA out of 54 ( which explains around 98.29% Variablility within the model) and the second model with 40 PCA’s out of 54 ( which explain around 99.8% of the variability)</p>

<p>Model 1 (ModelFit1.PCA30 ) - Applying Random Forest Algorithm to the first 30 Principal Components. Below is the time taken to compute the model</p>

<pre><code>##    user  system elapsed 
##   28.01    0.25   28.36</code></pre>

<p>Following are the specifics of the Model with 30 PC</p>

<pre><code>## 
## Call:
##  randomForest(formula = Training$class ~ ., data = pcompTraining) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 5
## 
##         OOB estimate of  error rate: 2.05%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 3880   12    6    5    3 0.006656426
## B   38 2588   25    3    4 0.026335591
## C    6   26 2344   20    0 0.021702838
## D    3    0   95 2147    7 0.046625222
## E    1    5   10   13 2496 0.011485149</code></pre>

<p>Model 2 (ModelFit2.PCA40 ) - Applying Random Forest Algorithm to the first 40 Principal Components. Below is the time taken to compute the model</p>

<pre><code>##    user  system elapsed 
##   34.78    0.16   35.05</code></pre>

<p>Following are the specifics of the Model with 40 PC</p>

<pre><code>## 
## Call:
##  randomForest(formula = Training$class ~ ., data = pcompTraining) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 6
## 
##         OOB estimate of  error rate: 1.86%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 3896    5    3    1    1 0.002560164
## B   50 2578   24    2    4 0.030097818
## C    5   22 2347   21    1 0.020450751
## D    3    1   79 2162    7 0.039964476
## E    0    8    8   11 2498 0.010693069</code></pre>

<p>Model 3 (ModelFit3.RF) - Applying Random Forest Algorithm to the data without any PreProcessing. Below is the time taken to compute the model</p>

<pre><code>##    user  system elapsed 
##   36.90    0.10   37.03</code></pre>

<p>Following are the specifics of the Model with no data preprocessing</p>

<pre><code>## 
## Call:
##  randomForest(formula = class ~ ., data = Training) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 7
## 
##         OOB estimate of  error rate: 0.27%
## Confusion matrix:
##      A    B    C    D    E  class.error
## A 3905    0    0    0    1 0.0002560164
## B    6 2649    3    0    0 0.0033860045
## C    0    6 2390    0    0 0.0025041736
## D    0    0   13 2236    3 0.0071047957
## E    0    0    0    5 2520 0.0019801980</code></pre>

<p>Now Preparing the Principal Componets for the Testing Datasets</p>

<p>Now , Applying the testing datasets to the respective Models to Predict the Outcome</p>

<p>Now Evaluating the confusion matrix for all the 3 model Fit .</p>

<pre><code>confMat.PCA30 # Confusion Matrix for Model with 30 PCA</code></pre>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1666    2    3    3    0
##          B   19 1105   14    0    1
##          C    0   12 1008    5    1
##          D    0    1   45  917    1
##          E    0    4    3    5 1070
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9798          
##                  95% CI : (0.9759, 0.9832)
##     No Information Rate : 0.2863          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9744          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9887   0.9831   0.9394   0.9860   0.9972
## Specificity            0.9981   0.9929   0.9963   0.9905   0.9975
## Pos Pred Value         0.9952   0.9701   0.9825   0.9512   0.9889
## Neg Pred Value         0.9955   0.9960   0.9866   0.9974   0.9994
## Prevalence             0.2863   0.1910   0.1823   0.1580   0.1823
## Detection Rate         0.2831   0.1878   0.1713   0.1558   0.1818
## Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
## Balanced Accuracy      0.9934   0.9880   0.9678   0.9883   0.9974</code></pre>

<pre><code>confMat.PCA40 # Confusion Matrix for Model with 40 PCA</code></pre>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1671    1    1    1    0
##          B   19 1107   13    0    0
##          C    2   10 1008    5    1
##          D    0    0   38  924    2
##          E    0    7    3    3 1069
## 
## Overall Statistics
##                                           
##                Accuracy : 0.982           
##                  95% CI : (0.9783, 0.9852)
##     No Information Rate : 0.2875          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9772          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9876   0.9840   0.9483   0.9904   0.9972
## Specificity            0.9993   0.9933   0.9963   0.9919   0.9973
## Pos Pred Value         0.9982   0.9719   0.9825   0.9585   0.9880
## Neg Pred Value         0.9950   0.9962   0.9887   0.9982   0.9994
## Prevalence             0.2875   0.1912   0.1806   0.1585   0.1822
## Detection Rate         0.2839   0.1881   0.1713   0.1570   0.1816
## Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
## Balanced Accuracy      0.9934   0.9886   0.9723   0.9911   0.9973</code></pre>

<pre><code>confMat.RF  # Confusion Matrix for Model with no data preprocessing </code></pre>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1674    0    0    0    0
##          B    1 1137    1    0    0
##          C    0    5 1021    0    0
##          D    0    0    9  955    0
##          E    0    0    0    3 1079
## 
## Overall Statistics
##                                          
##                Accuracy : 0.9968         
##                  95% CI : (0.995, 0.9981)
##     No Information Rate : 0.2846         
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
##                                          
##                   Kappa : 0.9959         
##  Mcnemar's Test P-Value : NA             
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9994   0.9956   0.9903   0.9969   1.0000
## Specificity            1.0000   0.9996   0.9990   0.9982   0.9994
## Pos Pred Value         1.0000   0.9982   0.9951   0.9907   0.9972
## Neg Pred Value         0.9998   0.9989   0.9979   0.9994   1.0000
## Prevalence             0.2846   0.1941   0.1752   0.1628   0.1833
## Detection Rate         0.2845   0.1932   0.1735   0.1623   0.1833
## Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
## Balanced Accuracy      0.9997   0.9976   0.9946   0.9975   0.9997</code></pre>

<p>Consolidating the data for all the 3 models in a single data frame for comparisons</p>

<pre><code>##                  Accuracy ElapsedTime
## ModelFit1.PCA30 0.9797791       28.36
## ModelFit1.PCA40 0.9819881       35.05
## ModelFit1.RF    0.9967715       37.03</code></pre>

<p>We see that the PCA model with 30 Principal Componets suffers from an accuracy trade off as compared to Model without any PreProcessing . However , if we look at the execution time we observer that there is a significant execution time gain in PCA30 Model (ModelFit1.PCA30) with respect to the Model without any PreProcessing (ModelFit3.RF).</p>

<p>For the case in discussion here, we will consider the solution that has the maximum Overall Accuracy. We will go ahead with the model with no data preprocessing (ModelFit3.RF).</p>

<p>Now , Importing the Validation data and predicting the results through model ModelFit3.RF</p>

<pre><code>Validation &lt;- read.csv("./pml-testing.csv")
ValResult &lt;- predict(ModelFit3.RF , Validation)</code></pre>

<p>Submitted the Validation result for final evaluation .</p>

<p></p>







<p></p>
        </section>

        <aside id="sidebar">
          <a href="https://github.com/DragFlick/datasciencecoursera/zipball/master" class="button">
            <small>Download</small>
            .zip file
          </a>
          <a href="https://github.com/DragFlick/datasciencecoursera/tarball/master" class="button">
            <small>Download</small>
            .tar.gz file
          </a>

          <p class="repo-owner"><a href="https://github.com/DragFlick/datasciencecoursera"></a> is maintained by <a href="https://github.com/DragFlick">DragFlick</a>.</p>

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the Architect theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.</p>
        </aside>
      </div>
    </div>

  
  </body>
</html>
